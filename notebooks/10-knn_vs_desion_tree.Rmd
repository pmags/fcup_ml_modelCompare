---
editor_options:
  chunk_output_type: console
---

# Linear Discriminante Analysis vs Quadratic Discriminant Analysis
Linear Discriminant Analysis
Assumptions:

  knn assumes normally distributed data and a class-specific mean vector.
knn assumes a common covariance matrix. So, a covariance matrix that is common to all classes in a data set.
When these assumptions hold, then knn approximates the Bayes classifier very closely and the discriminant function produces a linear decision boundary. However, knn also achieves good performances when these assumptions do not hold and a common covariance matrix among groups and normality are often violated.

Quadratic Discriminant Analysis
Assumptions:

  Observation of each class is drawn from a normal distribution (same as knn).
DT assumes that each class has its own covariance matrix (different from knn).
When these assumptions hold, DT approximates the Bayes classifier very closely and the discriminant function produces a quadratic decision boundary.


```{r  echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE}

knitr::opts_chunk$set(fig.align="center", echo=FALSE, fig.show = "hold")
source("./scripts/helper.R", local = TRUE, encoding = "UTF-8")

```

```{r include=FALSE}
# libraries
library(tidyverse)
library(tidymodels)
library(workflowsets)
library(gridExtra)

# set global seed for reproducibility
set.seed(123)

```


```{r}
# knn

l_mu_1 <- list(
  "g1" = c(2,2), 
  "g2" = c(3,6),
  "g3" = c(5,4)
  )

l_cvm_1 <- list( 
  "covg1" = matrix(c(1,0,0,1),2,2),
  "covg2" = matrix(c(1,-0.4,-0.4,1),2,2),
  "covg3" = matrix(c(1,0.2,0.2,1),2,2)
  )

l_w_1 <- list(
  "wg1" = 1/3, 
  "wg2" = 1/3,
  "wg3" = 1/3
  )


decision_1 <- function(x1,x2, l_mu_1, l_cvm_1){
  
l_mu_1 <- list(
  "g1" = c(2,2), 
  "g2" = c(3,6),
  "g3" = c(5,4)
  )

l_cvm_1 <- list( 
  "covg1" = matrix(c(1,0,0,1),2,2),
  "covg2" = matrix(c(1,-0.4,-0.4,1),2,2),
  "covg3" = matrix(c(1,0.2,0.2,1),2,2)
  )
  
  px_0 <- dmvnorm(c(x1,x2), mean = l_mu_1[[1]], sigma = l_cvm_1[[1]]) * 1/3 
  px_1 <- dmvnorm(c(x1,x2), mean = l_mu_1[[2]], sigma = l_cvm_1[[2]]) * 1/3
  px_2 <- dmvnorm(c(x1,x2), mean = l_mu_1[[3]], sigma = l_cvm_1[[3]]) * 1/3
  
  g <- case_when(
    
    px_0 > px_1 & px_0 > px_2 ~ 0,
    px_1 > px_0 & px_1 > px_2 ~ 1,
    px_2 > px_0 & px_2 > px_1 ~ 2,
    TRUE ~ 2
  )
  
  return(g)
}

dataset_knn <- dataset_gen_mvnorm(l_mu_1, l_cvm_1, l_w_1, class_fun = decision_1, n_g = 3)


```

```{r}

l_mu_2 <- list(
    "g1" = c(1,2), 
    "g2" = c(2,2),
    "g3" = c(3,4)
  )

l_cvm_2 <- list( 
  "covg1" = matrix(c(1,0,0,1),2,2),
  "covg2" = matrix(c(1,-0.4,-0.4,1),2,2),
  "covg3" = matrix(c(1,0.2,0.2,1),2,2)
  )
  
l_w_2 <- list(
  "wg1" = 1/3, 
  "wg2" = 1/3,
  "wg3" = 1/3
  )


decision_2 <- function(x1,x2, l_mu_2, l_cvm_2){
  
l_mu_2 <- list(
    "g1" = c(1,2), 
    "g2" = c(2,2),
    "g3" = c(3,4)
  )

l_cvm_2 <- list( 
  "covg1" = matrix(c(1,0,0,1),2,2),
  "covg2" = matrix(c(1,-0.4,-0.4,1),2,2),
  "covg3" = matrix(c(1,0.2,0.2,1),2,2)
  )
  
  px_0 <- dmvnorm(c(x1,x2), mean = l_mu_2[[1]], sigma = l_cvm_2[[1]])  
  px_1 <- dmvnorm(c(x1,x2), mean = l_mu_2[[2]], sigma = l_cvm_2[[2]]) 
  px_2 <- dmvnorm(c(x1,x2), mean = l_mu_2[[3]], sigma = l_cvm_2[[3]])
  
  g <- case_when(
    
    px_0 > px_1 & px_0 > px_2 ~ 0,
    px_1 > px_0 & px_1 > px_2 ~ 1,
    px_2 > px_0 & px_2 > px_1 ~ 2,
    TRUE ~ 2
  )
  
  return(g)
}

dataset_DT <- dataset_gen_mvnorm(l_mu_2, l_cvm_2, l_w_2, class_fun = decision_2, n_g = 3)

```

```{r}

grid.arrange(
  dataset_knn$border_plot, 
  dataset_DT$border_plot, 
  nrow = 1,
  top = "Optimal decision border")

```


## Model fitting

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis eu dictum lorem, et placerat dui. Donec porttitor posuere nisi, non tempor tellus ornare ut. Vestibulum vehicula libero eget consequat lobortis. Suspendisse vel arcu et urna iaculis mattis. Nulla ut mattis est. Pellentesque eu eleifend augue. Maecenas placerat tortor tincidunt risus rutrum tincidunt. 

```{r}
# define workflows

### knn

# 1. specify the model

nearest_neighbor_kknn_spec <-
  nearest_neighbor(neighbors = 3) %>%
  set_engine('kknn') %>%
  set_mode('classification')




# 2. preprocessing 
preprocess <- 
  recipe(g ~ x1 + x2 , data = dataset_knn$dataset)
  
# 3, Buildworkflow
nearest_neighbor_kknn_wflow <- 
  workflow() %>% 
  add_model(nearest_neighbor_kknn_spec) %>% 
  add_recipe(preprocess)


### DT

# 1. specify the model
decision_tree_rpart_spec <-
  decision_tree() %>%
  set_engine('rpart') %>%
  set_mode('classification')



# 2. preprocessing 
preprocess <- 
  recipe(g ~ x1 + x2 , data = dataset_DT$dataset)
  
# 3, Buildworkflow
decision_tree_rpart_wflow <- 
  workflow() %>% 
  add_model(decision_tree_rpart_spec) %>% 
  add_recipe(preprocess)

```


```{r}

data <- list(data_knn=dataset_knn, data_DT=dataset_DT)
workflows <- list(knn=nearest_neighbor_kknn_wflow , DT = decision_tree_rpart_wflow)

compare_fit <- model_fit_compare(data = data, workflows = workflows)

```


## Compare results

```{r}

## Metrics logistic model:
## using yardstick package for confusion matrix and accuracy
## using yardstick for roc curve and plots

## knn

metrics_ds1_knn <- 
  model_metrics(test_data = compare_fit$models$test$dataset1, 
                model = compare_fit$models$models$dataset1$knn)

metrics_ds2_knn <- 
  model_metrics(test_data = compare_fit$models$test$dataset2, 
                model = compare_fit$models$models$dataset2$knn)


## DT

metrics_ds1_DT <- 
  model_metrics(test_data = compare_fit$models$test$dataset1, 
                model = compare_fit$models$models$dataset1$DT)

metrics_ds2_DT <- 
  model_metrics(test_data = compare_fit$models$test$dataset2, 
                model = compare_fit$models$models$dataset2$DT)

```


```{r}

# logistic regression metrics during training

train_metrics_ds1_knn <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset1$knn, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

train_metrics_ds2_knn <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset2$knn, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()


# knn  performance during training

train_metrics_ds1_DT <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset1$DT, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

train_metrics_ds2_DT <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset2$DT, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

```

The plots below show the resulting decision boundaries

```{r}

## compare results

grid.arrange(
  compare_fit$plots$model_decision$dataset1$knn + labs(title = "dataset 1 - knn"),
  compare_fit$plots$model_decision$dataset1$DT + labs(title = "dataset 1 - DT"),
  compare_fit$plots$model_decision$dataset2$knn + labs(title = "dataset 2 - knn"),
  compare_fit$plots$model_decision$dataset2$DT + labs(title = "dataset 2 - DT"),
  nrow = 2,
  top = "Aplying a svm_linearistic model to both datasets",
  bottom = grid::textGrob(
    "Colored region represents the decision area of the model. Purple line represents the decision border. Visually is possible to conclude that the svm_linearistic model fits better a linear  frontier while struggling when facing a curved frontier",
    gp = grid::gpar(fontface = 3, fontsize = 9)
    )
  )

```

The plots shows the evolution of key metrics over crossvalidation trainning


```{r}

grid.arrange(
  train_metrics_ds1_knn + labs(title = "dataset 1 - knn"), 
  train_metrics_ds1_DT + labs(title = "dataset 1 - DT"), 
  train_metrics_ds2_knn + labs(title = "dataset 2 - knn"),
  train_metrics_ds2_DT + labs(title = "dataset 2 - DT"), 
  nrow = 2,
  top = "Metrics over different folds",
  bottom = grid::textGrob(
      "Right plots reflect trainning over linear border dataset and left plots reflect a quadractic border",
      gp = grid::gpar(fontface = 3, fontsize = 9)
      )
)

```


The plots show the metrics between different models

```{r}

grid.arrange(
  metrics_ds1_knn$cf_plot ,
  metrics_ds1_DT$cf_plot ,
  metrics_ds2_knn$cf_plot ,
  metrics_ds2_DT$cf_plot ,
  nrow = 2,
  top = "Confusion Matrix"
)


```


```{r}

grid.arrange(
  metrics_ds1_knn$roc_curve ,
  metrics_ds1_DT$roc_curve ,
  metrics_ds2_knn$roc_curve ,
  metrics_ds2_DT$roc_curve ,
  nrow = 2,
  top = "ROC curves"
)

  metrics_ds1_knn$auc_roc
  metrics_ds1_DT$auc_roc
  metrics_ds2_knn$auc_roc
  metrics_ds2_DT$auc_roc

```


