---
editor_options:
  chunk_output_type: console
---

# Nearest neighbour vs. decision tree
K-nearest neighbors
K-nearest neighbors is a non-parametric method used for classification and regression. It is one of the most easy ML technique used. It is a lazy learning model, with local approximation.
Assumptions :
There should be clear understanding about the input domain.
feasibly moderate sample size (due to space and time constraints).
colinearity and outliers should be treated prior to training.
Comparison with other models :

Decision Tree
Decision tree is a tree based algorithm used to solve regression and classification problems. An inverted tree is framed which is branched off from a homogeneous probability distributed root node, to highly heterogeneous leaf nodes, for deriving the output. Regression trees are used for dependent variable with continuous values and classification trees are used for dependent variable with discrete values.
Advantages :
No preprocessing needed on data.
No assumptions on distribution of data.
Handles colinearity efficiently.
Decision trees can provide understandable explanation over the prediction.

Decision tree vs KNN :

Both are non-parametric methods.
Decision tree supports automatic feature interaction, whereas KNN cant.
Decision tree is faster due to KNNâ€™s expensive real time execution.

```{r  echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE}

knitr::opts_chunk$set(fig.align="center", echo=FALSE, fig.show = "hold")
source("./scripts/helper.R", local = TRUE, encoding = "UTF-8")

```

```{r include=FALSE}
# libraries
library(tidyverse)
library(tidymodels)
library(workflowsets)
library(gridExtra)

# set global seed for reproducibility
set.seed(123)

```

For dataset of KNN we chose a dataset with a similar distribution and dispersion between the class, to avoid the confusion of the model in the bodaries areas.
For dataset for decision tree,we use points with diffewrnet distribution and a very similar mean because the model do not have assumption in the variance of the datasets.
```{r}
# knn

l_mu_1 <- list(
  "g1" = c(2,2), 
  "g2" = c(3,6),
  "g3" = c(5,4)
  )

l_cvm_1 <- list( 
  "covg1" = matrix(c(1,0,0,1),2,2),
  "covg2" = matrix(c(1,-0.4,-0.4,1),2,2),
  "covg3" = matrix(c(1,0.2,0.2,1),2,2)
  )

l_w_1 <- list(
  "wg1" = 1/3, 
  "wg2" = 1/3,
  "wg3" = 1/3
  )


decision_1 <- function(x1,x2, l_mu_1, l_cvm_1){
  
l_mu_1 <- list(
  "g1" = c(2,2), 
  "g2" = c(3,6),
  "g3" = c(5,4)
  )

l_cvm_1 <- list( 
  "covg1" = matrix(c(1,0,0,1),2,2),
  "covg2" = matrix(c(1,-0.4,-0.4,1),2,2),
  "covg3" = matrix(c(1,0.2,0.2,1),2,2)
  )
  
  px_0 <- dmvnorm(c(x1,x2), mean = l_mu_1[[1]], sigma = l_cvm_1[[1]]) * 1/3 
  px_1 <- dmvnorm(c(x1,x2), mean = l_mu_1[[2]], sigma = l_cvm_1[[2]]) * 1/3
  px_2 <- dmvnorm(c(x1,x2), mean = l_mu_1[[3]], sigma = l_cvm_1[[3]]) * 1/3
  
  g <- case_when(
    
    px_0 > px_1 & px_0 > px_2 ~ 0,
    px_1 > px_0 & px_1 > px_2 ~ 1,
    px_2 > px_0 & px_2 > px_1 ~ 2,
    TRUE ~ 2
  )
  
  return(g)
}

dataset_knn <- dataset_gen_mvnorm(l_mu_1, l_cvm_1, l_w_1, class_fun = decision_1, n_g = 3)


```

```{r}

l_mu_2 <- list(
    "g1" = c(1,2), 
    "g2" = c(2,2),
    "g3" = c(3,4)
  )

l_cvm_2 <- list( 
  "covg1" = matrix(c(1,0,0,1),2,2),
  "covg2" = matrix(c(1,-0.4,-0.4,1),2,2),
  "covg3" = matrix(c(1,0.2,0.2,1),2,2)
  )
  
l_w_2 <- list(
  "wg1" = 1/3, 
  "wg2" = 1/3,
  "wg3" = 1/3
  )


decision_2 <- function(x1,x2, l_mu_2, l_cvm_2){
  
l_mu_2 <- list(
    "g1" = c(1,2), 
    "g2" = c(2,2),
    "g3" = c(3,4)
  )

l_cvm_2 <- list( 
  "covg1" = matrix(c(1,0,0,1),2,2),
  "covg2" = matrix(c(1,-0.4,-0.4,1),2,2),
  "covg3" = matrix(c(1,0.2,0.2,1),2,2)
  )
  
  px_0 <- dmvnorm(c(x1,x2), mean = l_mu_2[[1]], sigma = l_cvm_2[[1]])  
  px_1 <- dmvnorm(c(x1,x2), mean = l_mu_2[[2]], sigma = l_cvm_2[[2]]) 
  px_2 <- dmvnorm(c(x1,x2), mean = l_mu_2[[3]], sigma = l_cvm_2[[3]])
  
  g <- case_when(
    
    px_0 > px_1 & px_0 > px_2 ~ 0,
    px_1 > px_0 & px_1 > px_2 ~ 1,
    px_2 > px_0 & px_2 > px_1 ~ 2,
    TRUE ~ 2
  )
  
  return(g)
}

dataset_DT <- dataset_gen_mvnorm(l_mu_2, l_cvm_2, l_w_2, class_fun = decision_2, n_g = 3)

```

```{r}

grid.arrange(
  dataset_knn$border_plot, 
  dataset_DT$border_plot, 
  nrow = 1,
  top = "Optimal decision border")

```


## Model fitting
 

```{r}
# define workflows

### knn

# 1. specify the model

nearest_neighbor_kknn_spec <-
  nearest_neighbor(neighbors = 3) %>%
  set_engine('kknn') %>%
  set_mode('classification')




# 2. preprocessing 
preprocess <- 
  recipe(g ~ x1 + x2 , data = dataset_knn$dataset)
  
# 3, Buildworkflow
nearest_neighbor_kknn_wflow <- 
  workflow() %>% 
  add_model(nearest_neighbor_kknn_spec) %>% 
  add_recipe(preprocess)


### DT

# 1. specify the model
decision_tree_rpart_spec <-
  decision_tree() %>%
  set_engine('rpart') %>%
  set_mode('classification')



# 2. preprocessing 
preprocess <- 
  recipe(g ~ x1 + x2 , data = dataset_DT$dataset)
  
# 3, Buildworkflow
decision_tree_rpart_wflow <- 
  workflow() %>% 
  add_model(decision_tree_rpart_spec) %>% 
  add_recipe(preprocess)

```


```{r}

data <- list(data_knn=dataset_knn, data_DT=dataset_DT)
workflows <- list(knn=nearest_neighbor_kknn_wflow , DT = decision_tree_rpart_wflow)

compare_fit <- model_fit_compare(data = data, workflows = workflows)

```


## Compare results

```{r}

## Metrics logistic model:
## using yardstick package for confusion matrix and accuracy
## using yardstick for roc curve and plots

## knn

metrics_ds1_knn <- 
  model_metrics(test_data = compare_fit$models$test$dataset1, 
                model = compare_fit$models$models$dataset1$knn)

metrics_ds2_knn <- 
  model_metrics(test_data = compare_fit$models$test$dataset2, 
                model = compare_fit$models$models$dataset2$knn)


## DT

metrics_ds1_DT <- 
  model_metrics(test_data = compare_fit$models$test$dataset1, 
                model = compare_fit$models$models$dataset1$DT)

metrics_ds2_DT <- 
  model_metrics(test_data = compare_fit$models$test$dataset2, 
                model = compare_fit$models$models$dataset2$DT)

```


```{r}

# logistic regression metrics during training

train_metrics_ds1_knn <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset1$knn, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

train_metrics_ds2_knn <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset2$knn, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()


# knn  performance during training

train_metrics_ds1_DT <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset1$DT, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

train_metrics_ds2_DT <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset2$DT, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

```

The plots below show the resulting decision boundaries

```{r}

## compare results

grid.arrange(
  compare_fit$plots$model_decision$dataset1$knn + labs(title = "dataset 1 - knn"),
  compare_fit$plots$model_decision$dataset1$DT + labs(title = "dataset 1 - DT"),
  compare_fit$plots$model_decision$dataset2$knn + labs(title = "dataset 2 - knn"),
  compare_fit$plots$model_decision$dataset2$DT + labs(title = "dataset 2 - DT"),
  nrow = 2,
  top = "Aplying a svm_linearistic model to both datasets",
  bottom = grid::textGrob(
    "Colored region represents the decision area of the model. Purple line represents the decision border. Visually is possible to conclude that the svm_linearistic model fits better a linear  frontier while struggling when facing a curved frontier",
    gp = grid::gpar(fontface = 3, fontsize = 9)
    )
  )

```
In the above graphs

The plots shows the evolution of key metrics over crossvalidation trainning


```{r}

grid.arrange(
  train_metrics_ds1_knn + labs(title = "dataset 1 - knn"), 
  train_metrics_ds1_DT + labs(title = "dataset 1 - DT"), 
  train_metrics_ds2_knn + labs(title = "dataset 2 - knn"),
  train_metrics_ds2_DT + labs(title = "dataset 2 - DT"), 
  nrow = 2,
  top = "Metrics over different folds",
  bottom = grid::textGrob(
      "Right plots reflect trainning over linear border dataset and left plots reflect a quadractic border",
      gp = grid::gpar(fontface = 3, fontsize = 9)
      )
)

```


The plots show the metrics between different models

```{r}

grid.arrange(
  metrics_ds1_knn$cf_plot ,
  metrics_ds1_DT$cf_plot ,
  metrics_ds2_knn$cf_plot ,
  metrics_ds2_DT$cf_plot ,
  nrow = 2,
  top = "Confusion Matrix"
)


```


```{r}

grid.arrange(
  metrics_ds1_knn$roc_curve ,
  metrics_ds1_DT$roc_curve ,
  metrics_ds2_knn$roc_curve ,
  metrics_ds2_DT$roc_curve ,
  nrow = 2,
  top = "ROC curves"
)

  metrics_ds1_knn$auc_roc
  metrics_ds1_DT$auc_roc
  metrics_ds2_knn$auc_roc
  metrics_ds2_DT$auc_roc

```


