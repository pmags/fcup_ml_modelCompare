---
editor_options:
  chunk_output_type: console
---

# logistic vs knn


```{r  echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE}

knitr::opts_chunk$set(fig.align="center", echo=FALSE, fig.show = "hold")
source("./scripts/helper.R", local = TRUE, encoding = "UTF-8")

```

```{r include=FALSE}
# libraries
library(tidyverse)
library(tidymodels)
library(workflowsets)
library(gridExtra)

# set global seed for reproducibility
set.seed(123)

```


```{r}

decision_fun_linear <- function(x1, x2){
  res <- ifelse(x2 >= x1, 1, 0)
  return(res)
}

decision_fun_quadratic <- function(x1, x2){
  res <- ifelse(x2 >= abs( (1.2 * x1 - 5)^2 + 2 ), 1, 0)
  return(res)
}

dataset_linear <- dataset_gen_runif(class_fun = decision_fun_linear)
dataset_quadratic <- dataset_gen_runif(class_fun = decision_fun_quadratic)

grid.arrange(
  dataset_linear$border_plot, 
  dataset_quadratic$border_plot, 
  nrow = 1,
  top = "Optimal decision border")

```


```{r}

l_mu <- list(
  "g1" = c(5,3), 
  "g2" = c(3,5)
  )

l_cvm <- list( 
  "covg1" = matrix(c(1,0,0,1),2,2),
  "covg2" = matrix(c(1,-0.4,-0.4,1),2,2)
  )

l_w <- list(
  "wg1" = 0.5, 
  "wg2" = 0.5
  )


decision <- function(x1,x2, l_mu, l_cvm){
  
  l_mu <- list(
    "g1" = c(5,3), 
    "g2" = c(3,5)
  )
  
  l_cvm <- list( 
    "covg1" = matrix(c(1,0,0,1),2,2),
    "covg2" = matrix(c(1,-0.4,-0.4,1),2,2)
  )
  
  px_0 <- dmvnorm(c(x1,x2), mean = l_mu[[1]], sigma = l_cvm[[1]]) * 0.5 
  px_1 <- dmvnorm(c(x1,x2), mean = l_mu[[2]], sigma = l_cvm[[2]]) * 0.5
  
  
  g <- case_when(
    
    px_0 > px_1 ~ 0,
    TRUE ~ 1
  )
  
  return(g)
}

dataset_gen_mvnorm(l_mu, l_cvm, l_w, class_fun = decision)


```



```{r}

l_mu_2 <- list(
  "g1" = c(5,3), 
  "g2" = c(3,5),
  "g3" = c(1,2)
  )

l_cvm_2 <- list( 
  "covg1" = matrix(c(1,0,0,1),2,2),
  "covg2" = matrix(c(1,-0.4,-0.4,1),2,2),
  "covg3" = matrix(c(1,0.2,0.2,1),2,2)
  )

l_w_2 <- list(
  "wg1" = 1/3, 
  "wg2" = 1/3,
  "wg3" = 1/3
  )


decision_2 <- function(x1,x2, l_mu, l_cvm){
  
  l_mu <- list(
    "g1" = c(5,3), 
    "g2" = c(3,5),
    "g3" = c(1,2)
  )
  
  l_cvm <- list( 
    "covg1" = matrix(c(1,0,0,1),2,2),
    "covg2" = matrix(c(1,-0.4,-0.4,1),2,2),
    "covg3" = matrix(c(1,0.2,0.2,1),2,2)
  )
  
  px_0 <- dmvnorm(c(x1,x2), mean = l_mu[[1]], sigma = l_cvm[[1]])  
  px_1 <- dmvnorm(c(x1,x2), mean = l_mu[[2]], sigma = l_cvm[[2]]) 
  px_2 <- dmvnorm(c(x1,x2), mean = l_mu[[3]], sigma = l_cvm[[3]])
  
  g <- case_when(
    
    px_0 > px_1 & px_0 > px_2 ~ 0,
    px_1 > px_0 & px_1 > px_2 ~ 1,
    px_2 > px_0 & px_2 > px_1 ~ 2,
    TRUE ~ 2
  )
  
  return(g)
}

y <- dataset_gen_mvnorm(l_mu_2, l_cvm_2, l_w_2, class_fun = decision_2, n_g = 3)




```


```{r}

 train <- rbind(iris3[1:25,1:2,1],
                iris3[1:25,1:2,2],
                iris3[1:25,1:2,3])
 cl <- factor(c(rep("s",25), rep("c",25), rep("v",25)))
 
  require(MASS)

 test <- expand.grid(x=seq(min(train[,1]-1), max(train[,1]+1),
                           by=0.1),
                     y=seq(min(train[,2]-1), max(train[,2]+1), 
                           by=0.1))
 require(class)
 classif <- knn(train, test, cl, k = 3, prob=TRUE)
 prob <- attr(classif, "prob")
 
 require(dplyr)

 dataf <- bind_rows(mutate(test,
                           prob=prob,
                           cls="c",
                           prob_cls=ifelse(classif==cls,
                                           1, 0)),
                    mutate(test,
                           prob=prob,
                           cls="v",
                           prob_cls=ifelse(classif==cls,
                                           1, 0)),
                    mutate(test,
                           prob=prob,
                           cls="s",
                           prob_cls=ifelse(classif==cls,
                                           1, 0)))
 
 require(ggplot2)
 ggplot(dataf) +
    geom_point(aes(x=x, y=y, col=cls),
               data = mutate(test, cls=classif),
               size=1.2) + 
    geom_contour(aes(x=x, y=y, z=prob_cls, group=cls, color=cls),
                 bins=2,
                 data=dataf) +
    geom_point(aes(x=x, y=y, col=cls),
               size=3,
               data=data.frame(x=train[,1], y=train[,2], cls=cl))

```



```{r eval=FALSE}
# 1. specify the model
logistic_reg_glm_spec <-
  logistic_reg(mode = "classification") %>%
  set_engine('glm') 

# 2. preprocessing 
preprocess <- 
  recipe(y ~ x1 + x2 , data = dataset_logistic)
  
# 3, Buildworkflow
logit_wflow <- 
  workflow() %>% 
  add_model(logistic_reg_glm_spec) %>% 
  add_recipe(preprocess)

#4. Fit model
fit_control <- control_resamples(save_pred = TRUE, save_workflow = TRUE)

folds <- vfold_cv(dataset_logistic, v = 10)

logit_fit <- 
  logit_wflow %>% 
  fit_resamples(folds, verbose = TRUE, control = fit_control)


#5. Performance metrics over the validation set
collect_metrics(logit_fit)

```
 
