---
editor_options:
  chunk_output_type: console
---

# logistic vs knn

```{r  echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE}

knitr::opts_chunk$set(fig.align="center", echo=FALSE, fig.show = "hold")
source("./scripts/helper.R", local = TRUE, encoding = "UTF-8")

```

```{r include=FALSE}
# libraries
library(tidyverse)
library(tidymodels)
library(workflowsets)
library(gridExtra)

# set global seed for reproducibility
set.seed(123)

```


## Dataset definition  

```{r}

decision_fun_linear <- function(x1, x2){
  res <- ifelse(x2 >= x1, 1, 0)
  return(res)
}

decision_fun_quadratic <- function(x1, x2){
  res <- ifelse(x2 >= abs( (1.2 * x1 - 5)^2 + 2 ), 1, 0)
  return(res)
}

dataset_linear <- dataset_gen_unif(class_fun = decision_fun_linear)
dataset_quadratic <- dataset_gen_unif(class_fun = decision_fun_quadratic)

grid.arrange(
  dataset_linear$border_plot, 
  dataset_quadratic$border_plot, 
  nrow = 1,
  top = "Optimal decision border")

```

## Model fitting


```{r}

# 0. Separate test and train

data_linear <- dataset_linear$dataset
data_linear$g <- factor(data_linear$g)

split <- initial_split(data_linear, prop = 0.8)

train_data_linear <- training(split)
test_data_linear <- testing(split)


data_quadratic <- dataset_quadratic$dataset
data_quadratic$g <- factor(data_quadratic$g)

split <- initial_split(data_quadratic, prop = 0.8)

train_data_quadratic <- training(split)
test_data_quadratic <- testing(split)

```



### Logistic regression


```{r}

## Create workflow

### Logistic regression -------------------------

 
# 1. specify the model
logistic_reg_glm_spec <-
  logistic_reg(mode = "classification") %>%
  set_engine('glm', family = "binomial") 

# 2. preprocessing 
preprocess <- 
  recipe(g ~ x1 + x2 , data = train_data_linear)
  
# 3, Buildworkflow
logit_wflow <- 
  workflow() %>% 
  add_model(logistic_reg_glm_spec) %>% 
  add_recipe(preprocess)

# 4. Fit model
fit_control <- control_resamples(save_pred = TRUE, save_workflow = TRUE)

folds_linear <- vfold_cv(train_data_linear, v = 10)
folds_quadratic <- vfold_cv(train_data_quadratic, v = 10)


logit_metrics_linear <- 
  logit_wflow %>% 
  fit_resamples(folds_linear, verbose = TRUE, control = fit_control)

logit_metrics_quadratic <- 
  logit_wflow %>% 
  fit_resamples(folds_quadratic, verbose = TRUE, control = fit_control)

# 5. Performance metrics over the validation set
logit_metrics_linear <- collect_metrics(logit_metrics_linear, summarize = FALSE)
logit_metrics_quadratic <- collect_metrics(logit_metrics_quadratic, summarize = FALSE)


# 6. Fits final model
logit_linear_fit <- 
  logit_wflow %>% 
  fit(train_data_linear)

logit_linear_model <- extract_fit_parsnip(logit_linear_fit)

logit_quadratic_fit <- 
  logit_wflow %>% 
  fit(train_data_quadratic)

logit_quadratic_model <- extract_fit_parsnip(logit_quadratic_fit)

```


 
### KNN

```{r}

### Knn--------------- -------------------------

# 1. specify the model
nearest_neighbor_kknn_spec <-
  nearest_neighbor() %>%
  set_engine('kknn') %>%
  set_mode('classification')

# 2. preprocessing 
preprocess <- 
  recipe(g ~ x1 + x2 , data = train_data_linear)
  
# 3, Buildworkflow
knn_wflow <- 
  workflow() %>% 
  add_model(nearest_neighbor_kknn_spec) %>% 
  add_recipe(preprocess)

```


## Compare results


```{r}

linear_metrics_plot <- 
  ggplot(logit_metrics_linear, aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

quadratic_metrics_plot <- 
  ggplot(logit_metrics_quadratic, aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

grid.arrange(
  linear_metrics_plot, 
  quadratic_metrics_plot, 
  nrow = 1,
  top = "Logit applied to different datasets")

```


```{r eval=FALSE}

log_results <- 
  test_data %>%
  bind_cols(
    predict(model, new_data = test_data),
    predict(model, new_data = test_data, type = "prob")
  ) %>% 
  mutate(
    .pred_1 = round(.pred_1, 3),
    .pred_0 = round(.pred_0, 3)
    )

```