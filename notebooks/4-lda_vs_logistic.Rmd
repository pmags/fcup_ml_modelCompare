---
editor_options:
  chunk_output_type: console
---

# Linear Discriminante Analysis vs Logistic Regression


```{r  echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE}

knitr::opts_chunk$set(fig.align="center", echo=FALSE, fig.show = "hold")
source("./scripts/helper.R", local = TRUE, encoding = "UTF-8")

```

```{r include=FALSE}

# libraries
library(workflowsets)
library(gridExtra)

# global seed for reproducibility
set.seed(123)

```


## Dataset definition  

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis eu dictum lorem, et placerat dui. Donec porttitor posuere nisi, non tempor tellus ornare ut. Vestibulum vehicula libero eget consequat lobortis. Suspendisse vel arcu et urna iaculis mattis. Nulla ut mattis est. Pellentesque eu eleifend augue. Maecenas placerat tortor tincidunt risus rutrum tincidunt. 


```{r}

## A pure linear boundary

decision <- function(x1, x2){
  res <- ifelse(x2 >= x1, 1, 0)
  return(res)
}

dataset_linear <- dataset_gen_unif(
  class_fun = decision, 
  size = 1000)


## A dataset with a multivariable normal distribution and similar covariance matrix

l_mu <- list(
  "g1" = c(6,2), 
  "g2" = c(2,6)
  )

l_cvm <- list( 
  "covg1" = matrix(c(1,0.4,0.4,1),2,2),
  "covg2" = matrix(c(1,-0.4,-0.4,1),2,2)
  )

l_w <- list(
  "wg1" = 0.5, 
  "wg2" = 0.5
  )


decision <- function(x1,x2){
  
  l_mu <- list(
    "g1" = c(6,2), 
    "g2" = c(2,6)
    )
  
  l_cvm <- list( 
    "covg1" = matrix(c(1,0.4,0.4,1),2,2),
    "covg2" = matrix(c(1,-0.4,-0.4,1),2,2)
    )
  
  px_0 <- dmvnorm(c(x1,x2), mean = l_mu[[1]], sigma = l_cvm[[1]]) * 0.5 
  px_1 <- dmvnorm(c(x1,x2), mean = l_mu[[2]], sigma = l_cvm[[2]]) * 0.5
  
  
  g <- case_when(
    
    px_0 > px_1 ~ 0,
    TRUE ~ 1
  )
  
  return(g)
}

dataset_normal_dist <- dataset_gen_mvnorm(
  l_mu = l_mu, 
  l_cvm = l_cvm, 
  l_w = l_w, 
  class_fun = decision)



grid.arrange(
  dataset_linear$border_plot, 
  dataset_normal_dist$border_plot, 
  nrow = 1,
  top = "Optimal decision border")

```


## Model fitting

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis eu dictum lorem, et placerat dui. Donec porttitor posuere nisi, non tempor tellus ornare ut. Vestibulum vehicula libero eget consequat lobortis. Suspendisse vel arcu et urna iaculis mattis. Nulla ut mattis est. Pellentesque eu eleifend augue. Maecenas placerat tortor tincidunt risus rutrum tincidunt. 

```{r}

# define workflows

### LDA

# 1. specify the model
discrim_linear_MASS_spec <-
  discrim_linear() %>%
  set_mode("classification") %>%
  set_engine("MASS")


# 2. preprocessing 
preprocess <- 
  recipe(g ~ x1 + x2 , data = dataset_linear$dataset)
  
# 3, Buildworkflow
lda_wflow <- 
  workflow() %>% 
  add_model(discrim_linear_MASS_spec) %>% 
  add_recipe(preprocess)


### Logistic

# 1. specify the model
logistic_reg_glm_spec <-
  logistic_reg(mode = "classification") %>%
  set_engine('glm', family = "binomial") 


# 2. preprocessing 
preprocess <- 
  recipe(g ~ x1 + x2 , data = dataset_linear$dataset)
  
# 3, Buildworkflow
log_wflow <- 
  workflow() %>% 
  add_model(logistic_reg_glm_spec) %>% 
  add_recipe(preprocess)

```


```{r}

data <- list(dataset_linear, dataset_normal_dist)
workflows <- list(log = log_wflow, lda = lda_wflow)

compare_fit <- model_fit_compare(data = data, workflows = workflows)

```

## Compare results

```{r}

## Metrics logistic model:
## using yardstick package for confusion matrix and accuracy
## using yardstick for roc curve and plots

## Logistic model

metrics_ds1_log <- 
  model_metrics(test_data = compare_fit$models$test$dataset1, 
                model = compare_fit$models$models$dataset1$log)

metrics_ds2_log <- 
  model_metrics(test_data = compare_fit$models$test$dataset2, 
                model = compare_fit$models$models$dataset2$log)

## lda model

metrics_ds1_lda <- 
  model_metrics(test_data = compare_fit$models$test$dataset1, 
                model = compare_fit$models$models$dataset1$lda)

metrics_ds2_lda <- 
  model_metrics(test_data = compare_fit$models$test$dataset2, 
                model = compare_fit$models$models$dataset2$lda)

```


```{r}

# logistic regression metrics during training

train_metrics_ds1_log <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset1$log, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

train_metrics_ds2_log <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset2$log, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()


# knn  performance during training

train_metrics_ds1_lda <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset1$lda, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

train_metrics_ds2_lda <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset2$lda, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

```

The plots below show the resulting decision boundaries

```{r}

## compare results

grid.arrange(
  compare_fit$plots$model_decision$dataset1$log,
  compare_fit$plots$model_decision$dataset1$lda,
  compare_fit$plots$model_decision$dataset2$log,
  compare_fit$plots$model_decision$dataset2$lda,
  nrow = 2,
  top = "Aplying a logistic model to both datasets",
  bottom = grid::textGrob(
    "Colored region represents the decision area of the model. Purple line represents the decision border. Visually is possible to conclude that the logistic model fits better a linear  frontier while struggling when facing a curved frontier",
    gp = grid::gpar(fontface = 3, fontsize = 9)
    )
  )

```

The plots shows the evolution of key metrics over crossvalidation trainning


```{r}

grid.arrange(
  train_metrics_ds1_log, 
  train_metrics_ds1_lda, 
  train_metrics_ds2_log,
  train_metrics_ds2_lda, 
  nrow = 2,
  top = "Metrics over different folds",
  bottom = grid::textGrob(
      "Right plots reflect trainning over linear border dataset and left plots reflect a quadractic border",
      gp = grid::gpar(fontface = 3, fontsize = 9)
      )
)

```


The plots show the metrics between different models

```{r}

grid.arrange(
  metrics_ds1_log$cf_plot ,
  metrics_ds1_lda$cf_plot ,
  metrics_ds2_log$cf_plot ,
  metrics_ds2_lda$cf_plot ,
  nrow = 2,
  top = "Confusion Matrix"
)


```


```{r}

grid.arrange(
  metrics_ds1_log$roc_curve ,
  metrics_ds1_lda$roc_curve ,
  metrics_ds2_log$roc_curve ,
  metrics_ds2_lda$roc_curve ,
  nrow = 2,
  top = "ROC curves"
)

```


## Conclusion

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis eu dictum lorem, et placerat dui. Donec porttitor posuere nisi, non tempor tellus ornare ut. Vestibulum vehicula libero eget consequat lobortis. Suspendisse vel arcu et urna iaculis mattis. Nulla ut mattis est. Pellentesque eu eleifend augue. Maecenas placerat tortor tincidunt risus rutrum tincidunt. 