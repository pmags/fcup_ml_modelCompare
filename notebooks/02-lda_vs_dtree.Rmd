---
editor_options:
  chunk_output_type: console
---

# Linear Discriminante Analysis vs Decision tree


```{r  echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE}

knitr::opts_chunk$set(fig.align="center", echo=FALSE, fig.show = "hold")
source("./scripts/helper.R", local = TRUE, encoding = "UTF-8")

```

```{r include=FALSE}

# libraries
library(workflowsets)
library(gridExtra)
library(discrim)

# global seed for reproducibility
set.seed(123)

```


## Dataset definition  

Similarly to Logistic regression, Linear Discriminant Analysis (LDA) estimates each class by modeling the conditional distribution $Pr(G = 1 | X)$, but using a different approach. While linear regression uses the *Logitisc function* for this purpose, LDA assumes each observation is drawan from a multivariated normal distribution with similar covariance and uses this distribution to model the conditional distribution. Therefore, on many ocasions, the output of both Logistic and LDA will be quite similar. *@hastie_09_elements-of.statistical-learning in their experience, this models give very similar results.*

Tree based methods take a very different approach to the problem. They involve *stratiying* or *segmenting* the predictor space into a number of simple regions.(see @James2013 pag-303). A metric like the mean or median is then used as predictor for each region or cut. 

This oposing technics have pronounced characteristics making then appropriate to dataset with specific characteristics. Whenever the classes are based on very pronounced cuts or classes, tree based approaches and their rule based classification will tend to fit best. On the other hand, on its simple form as decision tree, they tend to perform worse then tradional parametric conterparts as LDA when the classification border follows a clear distribution.

Therefore, we defined the comparing datasets as follows:

1. A dataset of 1000 experiments extracting, with repetition, pair of real numbers 1:100 all of them with equal probability (uniform distribution). Pairs above $X_{1} - X_{2} = 0$ are classified as **1** and **0** if below. In other words, we defined a hyperplane through the data and defined each class based on each point position towards that hyper plane.

> @James2013 In a p-dimensional space, a *hyperplane* is a flat affline subspace of dimension p-1. For instance, in two dimensions, a hyperplane is a flat one-dimensional subspace-in other words, a line. In two dimensions the hyperplane is defined as 

$$\beta_{0} + \beta_{1}X_{1} + \beta_{2}X_{2} = 0$$

2. A dataset of 1000 experiments extracting, with repetition, pair of real numbers 1:100 all of them with equal probability (uniform distribution). Pairs below a specific treshold (x1,x2) are classified as 1 and 0 for the rest. Considering for example x1 as weight and x2 as height would be equivalent as classifying every combination below a x1,x2 as "children" or "underweight".

```{r echo=TRUE}

decision_fun_linear <- function(x1, x2){
  res <- ifelse(x2 >= x1, 1, 0)
  return(res)
}

dataset_linear <- dataset_gen_unif(class_fun = decision_fun_linear, size = 1000)

decision_fun_normal <- function(x1, x2){
  
  mu <- c(6,6)
  cvar <- matrix(c(0.5,0,0,0.5), 2, 2)
  p <- mvtnorm::pmvnorm(c(x1,x2), mean = mu, sigma = cvar)
  
  res <- ifelse(p[1] <= 0.5, 1, 0)
  return(res)
}

dataset_dtree <- dataset_gen_unif(class_fun = decision_fun_normal)


grid.arrange(
  dataset_dtree$border_plot + labs(subtitle = "Segmented datase", color = ""), 
  dataset_linear$border_plot + labs(subtitle = "Linear border", color = ""), 
  nrow = 1,
  top = "Synthetic Generated Datasets",
  bottom = grid::textGrob(
    "Dashed line represent optimal bayes decision boundary",
    gp = grid::gpar(fontface = 3, fontsize = 9)
    )
  )

```

## Model fitting

The following workflow (using @R-tidymodels) was executed in order to fit and evaluate each model given the above defined datasets:

1. Train - Test split by 80% Train - 20% Test,

2. Define 10 random folds splitting Train and Validation,

3. Fit models to each fold,

4. Calculate Fold metrics,

5. Fit to all train data and extract model,

6. Create plots with estimated decision boundaries

The decision tree is fitted using the following default parameters:

 - Tree depth = 30
 - Minimal Node size = 2
 - Cost complexity = 0.01


```{r echo=TRUE, message=FALSE, warning=FALSE}
# define workflows

### LDA

# 1. specify the model
discrim_linear_MASS_spec <-
  discrim_linear() %>%
  set_mode("classification") %>%
  set_engine("MASS")

# 2. preprocessing 
preprocess <- 
  recipes::recipe(g ~ x1 + x2 , data = dataset_linear$dataset)
  

# 3, Buildworkflow
lda_wflow <- 
  workflows::workflow() %>% 
  workflows::add_model(discrim_linear_MASS_spec) %>% 
  workflows::add_recipe(preprocess)


### Decision tree

# 1. specify the model
decision_tree_rpart_spec <-
  decision_tree() %>% 
  set_engine("rpart") %>%
  set_mode("classification")

# 2. preprocessing 
preprocess <- 
  recipes::recipe(g ~ x1 + x2 , data = dataset_linear$dataset) # just to set the relation, irrelevant which dataset used
  
# 3, Buildworkflow
dtree_wflow <- 
  workflows::workflow() %>% 
  workflows::add_model(decision_tree_rpart_spec) %>% 
  workflows::add_recipe(preprocess)

```


```{r echo=TRUE, message=FALSE, warning=FALSE}

data <- list(dataset_linear, dataset_dtree)
workflows <- list(lda = lda_wflow , dtree = dtree_wflow)

compare_fit <- model_fit_compare(data = data, workflows = workflows)

```


## Compare results

```{r message=TRUE, warning=TRUE, include=FALSE}

## Metrics lda model:
## using yardstick package for confusion matrix and accuracy
## using yardstick for roc curve and plots

## lda model

metrics_ds1_lda <- 
  model_metrics(test_data = compare_fit$models$test$dataset1, 
                model = compare_fit$models$models$dataset1$lda)

metrics_ds2_lda <- 
  model_metrics(test_data = compare_fit$models$test$dataset2, 
                model = compare_fit$models$models$dataset2$lda)


## dtree model

metrics_ds1_dtree <- 
  model_metrics(test_data = compare_fit$models$test$dataset1, 
                model = compare_fit$models$models$dataset1$dtree)

metrics_ds2_dtree <- 
  model_metrics(test_data = compare_fit$models$test$dataset2, 
                model = compare_fit$models$models$dataset2$dtree)

```


```{r message=TRUE, warning=TRUE, include=FALSE}

# lda regression metrics during training

train_metrics_ds1_lda <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset1$lda, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

train_metrics_ds2_lda <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset2$lda, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()


# dtree  performance during training

train_metrics_ds1_dtree <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset1$dtree, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

train_metrics_ds2_dtree <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset2$dtree, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

```


```{r}

## compare results

grid.arrange(
  compare_fit$plots$model_decision$dataset1$lda + labs(subtitle = "Segmented border", color = ""),
  compare_fit$plots$model_decision$dataset1$dtree + labs(subtitle = "Linear border", color = ""),
  compare_fit$plots$model_decision$dataset2$lda ,
  compare_fit$plots$model_decision$dataset2$dtree,
  nrow = 2,
  top = "lda vs dtree",
  bottom = grid::textGrob(
    "Colored region represents the decision area of the model. Purple line represents the decision border.",
    gp = grid::gpar(fontface = 3, fontsize = 9)
    )
  )

```

As expected when facing a perfectly linear boundary the LDA outperformed the decision tree. Given its segmented approach a decision tree will try to fit an increasing number of segments into a line. In theory, if this process will let to continue without any limitation it would be possible for the process to define a significantly high number of segments that would very much resemble a line. This is hardly a computational efficient approach. (as said above the tree depth is 30).


```{r message=FALSE, warning=FALSE}

par(mfrow = c(1, 2))
rpart.plot(compare_fit[["models"]][["models"]][["dataset1"]][["dtree"]][["fit"]], main = "Linear border")
rpart.plot(compare_fit[["models"]][["models"]][["dataset2"]][["dtree"]][["fit"]], main = "Segmented ")

```

On the other hand LDA failed to capture a clear segmented are from the dataset since it tryied to fit a linear border into the data.


```{r echo=FALSE}

grid.arrange(
  train_metrics_ds1_lda + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)), 
  train_metrics_ds1_dtree+ theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)), 
  train_metrics_ds2_lda+ theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)),
  train_metrics_ds2_dtree+ theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)), 
  nrow = 2,
  top = "Metrics over different folds",
  bottom = grid::textGrob(
      "Right plots reflect trainning over linear border dataset and left plots reflect a segmented border",
      gp = grid::gpar(fontface = 3, fontsize = 9)
      )
)

```

Below the results on the test set which confirm our preliminary conclusions

```{r}

grid.arrange(
  metrics_ds1_lda$cf_plot ,
  metrics_ds1_dtree$cf_plot ,
  metrics_ds2_lda$cf_plot ,
  metrics_ds2_dtree$cf_plot ,
  nrow = 2,
  top = "Confusion Matrix"
)

```


```{r}

grid.arrange(
  metrics_ds1_lda$roc_curve ,
  metrics_ds1_dtree$roc_curve ,
  metrics_ds2_lda$roc_curve ,
  metrics_ds2_dtree$roc_curve ,
  nrow = 2,
  top = "ROC curves"
)

```


## Conclusion

Our analysis shows that when a clear segmentation of class exists then a decision tree can outperform LDA under certain conditions. 
