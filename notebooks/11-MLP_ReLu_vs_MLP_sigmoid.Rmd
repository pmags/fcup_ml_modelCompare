---
editor_options:
  chunk_output_type: console
---

# 11. MLP ReLu vs MLP sigmoid



```{r  echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE}

knitr::opts_chunk$set(fig.align="center", echo=FALSE, fig.show = "hold")
source("./scripts/helper.R", local = TRUE, encoding = "UTF-8")

```

```{r include=FALSE}

# libraries
library(workflowsets)
library(gridExtra)

# global seed for reproducibility
set.seed(123)

```


## Dataset definition  
A neural network will almost always have the same activation function in all hidden layers.

It is most unusual to vary the activation function through a network model.

Traditionally, the sigmoid activation function was the default activation function in the 1990s. Perhaps through the mid to late 1990s to 2010s, the Tanh function was the default activation function for hidden layers.

The hyperbolic tangent activation function typically performs better than the logistic sigmoid.(Page 195, Deep Learning, 2016)

Both the sigmoid and Tanh functions can make the model more susceptible to problems during training, via the so-called vanishing gradients problem.

The activation function used in hidden layers is typically chosen based on the type of neural network architecture.

Modern neural network models with common architectures, such as MLP and CNN, will make use of the ReLU activation function, or extensions.

In modern neural networks, the default recommendation is to use the rectified linear unit or ReLU (Page 174, Deep Learning, 2016.)

```{r}

decision_MLP_relu <- function(x1, x2){
  res <- ifelse((-5 + x1)^2 + (5 - x2)^2 > 4, 1, 0)
  return(res)
}

dataset_MLP_relu <- dataset_gen_unif(class_fun = decision_MLP_relu, size = 1000)

decision_MLP_sigmoid <- function(x1, x2){
  res <- ifelse(x2 >= abs( (1.2 * x1 - 5)^2 + 2 ), 1, 0)
  return(res)
}
dataset_MLP_sigmoid <- dataset_gen_unif(class_fun = decision_MLP_sigmoid, size = 1000)

grid.arrange(
  dataset_MLP_relu$border_plot, 
  dataset_MLP_sigmoid$border_plot, 
  nrow = 1,
  top = "Optimal decision border")

```

## Model fitting


```{r}
# define workflows

### MLP relu model 

# 1. specify the model

mlp_nnet_relu_spec <-
  mlp() %>%
  set_engine('nnet',hidden_units=2, learn_rate=0.01,activation="relu") %>%
  set_mode('classification')

# 2. preprocessing 
preprocess <- 
    recipe(g ~ x1 + x2 , data = dataset_MLP_relu$dataset)
  
# 3, Buildworkflow
mlp_nnet_relu_wflow <- 
  workflow() %>% 
  add_model(mlp_nnet_relu_spec) %>% 
  add_recipe(preprocess) 


### MLP sigmoid model

# 1. specify the model

mlp_nnet_sigmoid_spec <-
  mlp() %>%
  set_engine('nnet',hidden_units=2, learn_rate=0.01,activation="linear") %>%
  set_mode('classification')


# 2. preprocessing 
preprocess <- 
    recipe(g ~ x1 + x2 , data = dataset_MLP_sigmoid$dataset)
  
# 3. Buildworkflow
mlp_nnet_sigmoid_wflow <- 
  workflow() %>% 
  add_model(mlp_nnet_sigmoid_spec) %>% 
  add_recipe(preprocess)


```

```{r}

data <- list(dataset_MLP_relu, dataset_MLP_sigmoid)
workflows <- list(MLPrelu = mlp_nnet_relu_wflow, MLPsigmoid = mlp_nnet_sigmoid_wflow)

compare_fit <- model_fit_compare(data = data, workflows = workflows)

```



## Compare results

```{r}

## Metrics logistic model:
## using yardstick package for confusion matrix and accuracy
## using yardstick for roc curve and plots

## Logistic model

metrics_ds1_MLPrelu <-
  model_metrics(test_data = compare_fit$models$test$dataset1, 
                model = compare_fit$models$models$dataset1$MLPrelu)

metrics_ds2_MLPrelu<- 
  model_metrics(test_data = compare_fit$models$test$dataset2, 
                model = compare_fit$models$models$dataset2$MLPrelu)


## svm_radial model

metrics_ds1_MLPsigmoid <- 
  model_metrics(test_data = compare_fit$models$test$dataset1, 
                model = compare_fit$models$models$dataset1$MLPsigmoid)

metrics_ds2_MLPsigmoid <- 
  model_metrics(test_data = compare_fit$models$test$dataset2, 
                model = compare_fit$models$models$dataset2$MLPsigmoid)

```


```{r}

# logistic regression metrics during training

train_metrics_ds1_MLPrelu <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset1$MLPrelu, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

train_metrics_ds2_MLPrelu <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset2$MLPrelu, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()


# knn  performance during training

train_metrics_ds1_MLPsigmoid <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset1$MLPsigmoid, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

train_metrics_ds2_MLPsigmoid <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset2$MLPsigmoid, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

```

The plots below show the resulting decision boundaries

```{r}

## compare results

grid.arrange(
  compare_fit$plots$model_decision$dataset1$MLPrelu,
  compare_fit$plots$model_decision$dataset1$MLPsigmoid,
  compare_fit$plots$model_decision$dataset2$MLPrelu,
  compare_fit$plots$model_decision$dataset2$MLPsigmoid,
  nrow = 2,
  top = "Aplying a svm_linearistic model to both datasets",
  bottom = grid::textGrob("",
    gp = grid::gpar(fontface = 3, fontsize = 9)
    )
  )

```

The plots shows the evolution of key metrics over crossvalidation trainning


```{r}

grid.arrange(
  train_metrics_ds1_MLPrelu, 
  train_metrics_ds1_MLPsigmoid, 
  train_metrics_ds2_MLPrelu,
  train_metrics_ds2_MLPsigmoid, 
  nrow = 2,
  top = "Metrics over different folds",
  bottom = grid::textGrob(
      "",
      gp = grid::gpar(fontface = 3, fontsize = 9)
      )
)

```


The plots show the metrics between different models

```{r}

grid.arrange(
  metrics_ds1_MLPrelu$cf_plot ,
  metrics_ds1_MLPsigmoid$cf_plot ,
  metrics_ds2_MLPrelu$cf_plot ,
  metrics_ds2_MLPsigmoid$cf_plot ,
  nrow = 2,
  top = "Confusion Matrix"
)


```


```{r}

grid.arrange(
  metrics_ds1_MLPrelu$roc_curve ,
  metrics_ds1_MLPsigmoid$roc_curve ,
  metrics_ds2_MLPrelu$roc_curve ,
  metrics_ds2_MLPsigmoid$roc_curve ,
  nrow = 2,
  top = "ROC curves"
)

```


## Conclusion

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis eu dictum lorem, et placerat dui. Donec porttitor posuere nisi, non tempor tellus ornare ut. Vestibulum vehicula libero eget consequat lobortis. Suspendisse vel arcu et urna iaculis mattis. Nulla ut mattis est. Pellentesque eu eleifend augue. Maecenas placerat tortor tincidunt risus rutrum tincidunt. 