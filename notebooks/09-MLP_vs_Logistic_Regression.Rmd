---
editor_options:
  chunk_output_type: console
---

# MLP vs knn


```{r  echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE}

knitr::opts_chunk$set(fig.align="center", echo=FALSE, fig.show = "hold")
source("./scripts/helper.R", local = TRUE, encoding = "UTF-8")

```

```{r include=FALSE}

# libraries
library(workflowsets)
library(gridExtra)

# global seed for reproducibility
set.seed(123)

```


## Dataset definition  


In general ANN methods as semi-parametric methods have many advantages such as, allow a large number of variables in the model, no need to assumptions such as normality andâ€¦, finding the models despite missing data, detection of complex and nonlinear relationship between independent and dependent variables.

Although in theory and practical studies have been hinted ANN have better performance than statistical methods, but it has some disadvantage such as, the accuracy of the results depends largely on the size of the training set, requires the initialization and adjustment of many individual parameters to optimize the classification performance, standardized coefficients and odds ratios corresponding to each independent variable cannot be easily calculated, weights are generated in a neural network analysis, but their interpretation is difficult, the weights may be influenced by the program used to generate them.(Teshnizi SH, Ayatollahi SM. A Comparison of Logistic Regression Model and Artificial Neural Networks in Predicting of Student's Academic Failure. Acta Inform Med. 2015 Oct;23(5):296-300. doi: 10.5455/aim.2015.23.296-300. Epub 2015 Oct 5. PMID: 26635438; PMCID: PMC4639347.)

So, we expect that a MLP works better in a dataset with non-linear boundary, and the logistic regression will fits weel in a dataset with a linear boundary.



```{r}

decision_MLP <- function(x1, x2){
  res <- ifelse((-5 + x1)^2 + (5 - x2)^2 > 4, 1, 0)
  return(res)
}

dataset_MLP <- dataset_gen_unif(class_fun = decision_MLP, size = 1000)


l_mu <- list(
  "g1" = c(6,6), 
  "g2" = c(4,5)
  )

l_cvm <- list( 
  "covg1" = matrix(c(1,0.4,0.4,1),2,2),
  "covg2" = matrix(c(1,-0.4,-0.4,1),2,2)
  )

l_w <- list(
  "wg1" = 0.5, 
  "wg2" = 0.5
  )


decision <- function(x1,x2){
  
  l_mu <- list(
    "g1" = c(6,6), 
    "g2" = c(4,5)
    )
  
  l_cvm <- list( 
    "covg1" = matrix(c(1,0.4,0.4,1),2,2),
    "covg2" = matrix(c(1,-0.4,-0.4,1),2,2)
    )
  
  px_0 <- dmvnorm(c(x1,x2), mean = l_mu[[1]], sigma = l_cvm[[1]]) * 0.5 
  px_1 <- dmvnorm(c(x1,x2), mean = l_mu[[2]], sigma = l_cvm[[2]]) * 0.5
  
  
  g <- case_when(
    
    px_0 > px_1 ~ 0,
    TRUE ~ 1
  )
  
  return(g)
}

dataset_LR <- dataset_gen_mvnorm(
  l_mu = l_mu, 
  l_cvm = l_cvm, 
  l_w = l_w, 
  class_fun = decision)




grid.arrange(
  dataset_MLP$border_plot, 
  dataset_LR$border_plot, 
  nrow = 1,
  top = "Optimal decision border")

```


## Model fitting

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis eu dictum lorem, et placerat dui. Donec porttitor posuere nisi, non tempor tellus ornare ut. Vestibulum vehicula libero eget consequat lobortis. Suspendisse vel arcu et urna iaculis mattis. Nulla ut mattis est. Pellentesque eu eleifend augue. Maecenas placerat tortor tincidunt risus rutrum tincidunt. 

```{r}
# define workflows

### MLP model

# 1. specify the model

mlp_nnet_spec <-
  mlp() %>%
  set_engine('nnet',learn_rate = 0.001) %>%
  set_mode('classification')

# 2. preprocessing 
preprocess <- 
    recipe(g ~ x1 + x2 , data = dataset_MLP$dataset)
  
# 3, Buildworkflow
mlp_nnet_wflow <- 
  workflow() %>% 
  add_model(mlp_nnet_spec) %>% 
  add_recipe(preprocess)

### Logistic

# 1. specify the model
logistic_reg_glm_spec <-
  logistic_reg(mode = "classification") %>%
  set_engine('glm', family = "binomial") 


# 2. preprocessing 
preprocess <- 
  recipe(g ~ x1 + x2 , data = dataset_LR$dataset)
  
# 3, Buildworkflow
log_wflow <- 
  workflow() %>% 
  add_model(logistic_reg_glm_spec) %>% 
  add_recipe(preprocess)
```


```{r}

data <- list(dataset_MLP, dataset_LR)
workflows <- list(MLP = mlp_nnet_wflow, LR = log_wflow)

compare_fit <- model_fit_compare(data = data, workflows = workflows)

```


## Compare results

```{r}

## Metrics logistic model:
## using yardstick package for confusion matrix and accuracy
## using yardstick for roc curve and plots

## Logistic model

metrics_ds1_MLP <-
  model_metrics(test_data = compare_fit$models$test$dataset1, 
                model = compare_fit$models$models$dataset1$MLP)

metrics_ds2_MLP<- 
  model_metrics(test_data = compare_fit$models$test$dataset2, 
                model = compare_fit$models$models$dataset2$MLP)


## svm_radial model

metrics_ds1_LR <- 
  model_metrics(test_data = compare_fit$models$test$dataset1, 
                model = compare_fit$models$models$dataset1$LR)

metrics_ds2_LR <- 
  model_metrics(test_data = compare_fit$models$test$dataset2, 
                model = compare_fit$models$models$dataset2$LR)

```


```{r}

# logistic regression metrics during training

train_metrics_ds1_MLP <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset1$MLP, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

train_metrics_ds2_MLP <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset2$MLP, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()


# knn  performance during training

train_metrics_ds1_LR <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset1$LR, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

train_metrics_ds2_LR <- 
  ggplot(
    collect_metrics(
      compare_fit$models$fit_resample_train$dataset2$LR, 
      summarize = FALSE), 
    aes(x = id, y = .estimate, color= .metric)) + 
  geom_point() +
  theme_bw()

```

The plots below show the resulting decision boundaries

```{r}

## compare results

grid.arrange(
  compare_fit$plots$model_decision$dataset1$MLP,
  compare_fit$plots$model_decision$dataset1$LR,
  compare_fit$plots$model_decision$dataset2$MLP,
  compare_fit$plots$model_decision$dataset2$LR,
  nrow = 2,
  top = "Aplying a svm_linearistic model to both datasets",
  bottom = grid::textGrob(
    "Colored region represents the decision area of the model. Purple line represents the decision border. Visually is possible to conclude that the svm_linearistic model fits better a linear  frontier while struggling when facing a curved frontier",
    gp = grid::gpar(fontface = 3, fontsize = 9)
    )
  )

```
As expected, the MLP model had better result in the non-linear bondary dataset, while the other dataset had better results in the logistic regression, evan these difference is not so huge that in the case of the other dataset.

The plots shows the evolution of key metrics over crossvalidation trainning.


```{r}

grid.arrange(
  train_metrics_ds1_MLP, 
  train_metrics_ds1_LR, 
  train_metrics_ds2_MLP,
  train_metrics_ds2_LR, 
  nrow = 2,
  top = "Metrics over different folds",
  bottom = grid::textGrob(
      "",
      gp = grid::gpar(fontface = 3, fontsize = 9)
      )
)

```


The plots show the metrics between different models

```{r}

grid.arrange(
  metrics_ds1_MLP$cf_plot ,
  metrics_ds1_LR$cf_plot ,
  metrics_ds2_MLP$cf_plot ,
  metrics_ds2_LR$cf_plot ,
  nrow = 2,
  top = "Confusion Matrix"
)


```


```{r}

grid.arrange(
  metrics_ds1_MLP$roc_curve ,
  metrics_ds1_LR$roc_curve ,
  metrics_ds2_MLP$roc_curve ,
  metrics_ds2_LR$roc_curve ,
  nrow = 2,
  top = "ROC curves"
)

```


## Conclusion

In comparison with the conventional LR model, the ANN model was more accurate in general predicting tasks. Therefore, based on the results, it seems that for classification of a dichotomous dependent variable, artificial neural network methods are appropriate to be used.